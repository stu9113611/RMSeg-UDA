from pathlib import Path
from typing import Any, Optional

import torch
from ema_pytorch import EMA
from rich import print as rprint
from rich.progress import Progress
from rich.table import Table
from torch.utils.data import DataLoader

from engine import builder, ema, transform
from engine.category import Category
from engine.dataloader import ImgAnnDataset, RCSConfig, RCSImgAnnDataset
from engine.inferencer import Inferencer
from engine.logger import Logger
from engine.metric import Metrics
from engine.misc import NanException, set_seed
from engine.optimizer import AdamW, Optimizer
from engine.visualizer import IdMapVisualizer, ImgSaver


def train_iter(
    img: torch.Tensor,
    ann: torch.Tensor,
    model: torch.nn.Module,
    criterion: torch.nn.Module,
    optimizer: Optimizer,
    weight: float = 1.0,
    device: str = "cuda",
) -> dict[str, Any]:
    """Train the model with one batch.

    Args:
        img (torch.Tensor): Transformed image batch.
        ann (torch.Tensor): Transformed annotation batch.
        model (torch.nn.Module): Model to be trained.
        weight (float, optional): The weight of loss update. Defaults to 1.0.
        device (str): "cpu" or "cuda". Defaults to "cuda".

    Raises:
        NanException: Nan loss encounterd. And the model's parameters won't be updated.

    Returns:
        dict[str, Any]: results. key={"Loss", "Weight", "Img", "Ann", "Pred"}
    """
    results = {}
    model.train()

    img = img.to(device)
    ann = ann.to(device)

    optimizer.zero_grad()

    pred = model(img)
    loss = criterion(pred, ann).mean()

    results["Img"] = img
    results["Ann"] = ann
    results["Loss"] = loss.item()
    results["Weight"] = weight
    results["Pred"] = pred

    if torch.isnan(loss):
        raise NanException("NaN encountered during loss computing!")

    (loss * weight).backward()
    optimizer.step()

    return results


def pseudo_train_iter(
    img: torch.Tensor,
    model: torch.nn.Module,
    ema: EMA,
    criterion: torch.nn.Module,
    optimizer: Optimizer,
    strong_img: Optional[torch.Tensor] = None,
    soft_loss_computer: ema.SoftLossComputer = ema.NoThreshold(),
    weight: float = 1.0,
    entropy_loss_computer: ema.EntropyLossComputer = ema.BasicEntropy(),
    entropy_weight: float = 0.0,
    device: str = "cuda",
) -> dict[str, Any]:
    """Train the model with one pseudo batch generated by ema.

    Args:
        img (torch.Tensor): Tranformed image batch.
        model (torch.nn.Module): Model to be trained.
        ema (EMA): Exponential moving average teacher model.
        criterion (torch.nn.Module): Loss function.
        optimizer (Optimizer): The optimizer.
        soft_loss_computing (SoftLossComputing, optional): Computing strategy for pseudo annotation. Defaults to NoThresholdLoss().
        weight (float, optional): The weight of pseudo loss updating. Defaults to 1.0.
        entropy_weight (float, optional): The weight of entropy minimization. Defaults to 0.0.
        device (str, optional): "cpu" or "cuda". Defaults to "cuda".


    Raises:
        NanException: Nan loss encounterd. And the model's parameters won't be updated.

    Returns:
        dict[str, Any]: results. key={
            "Loss", "Weight", "Img", "Ann", "Ann Conf", "Pred", "Entropy", "Entropy Weight", "Entropy Map",
            {"Strong Img", "FixMatch Loss", "Strong Pred"}}
    """
    results = {}
    model.train()

    img = img.to(device)

    optimizer.zero_grad()

    pred = model(img)
    if strong_img is not None:
        strong_pred = model(strong_img.to(device))
        fixmatch_loss = (
            torch.nn.functional.cross_entropy(pred, strong_pred.softmax(1)) * 0.1
        )
        fixmatch_loss.backward(retain_graph=True)
        results["Strong Img"] = strong_img
        results["FixMatch Loss"] = fixmatch_loss.item()
        results["Strong Pred"] = strong_pred

    ema.train()
    with torch.no_grad():
        ema_pred = ema(img).softmax(1)
    loss = soft_loss_computer.compute(pred, ema_pred, criterion)
    entropy_map = entropy_loss_computer.compute(pred)
    entropy = entropy_map.mean()

    results["Img"] = img
    results["Ann Conf"], results["Ann"] = torch.max(ema_pred, dim=1)
    results["Loss"] = loss.item()
    results["Weight"] = weight
    results["Pred"] = pred
    results["Entropy"] = entropy.item()
    results["Entropy Weight"] = entropy_weight
    results["Entropy Map"] = entropy_map.detach()

    if torch.isnan(loss):
        raise NanException("NaN encountered during loss computing!")

    if torch.isnan(entropy):
        raise NanException("NaN encountered during entropy computing!")

    (loss * weight + entropy * entropy_weight).backward()
    optimizer.step()

    return results


class Validator:
    def __init__(
        self,
        dataloader: DataLoader,
        target_dataloader: DataLoader,
        criterion: torch.nn.Module,
        inferencer: Inferencer,
        metrics: Metrics,
        img_saver: ImgSaver,
        categories: list[Category],
        logger: Logger,
    ) -> None:
        self.dataloader = dataloader
        self.target_dataloader = target_dataloader
        self.criterion = criterion
        self.inferencer = inferencer
        self.metrics = metrics
        self.img_saver = img_saver
        self.categories = categories
        self.logger = logger

    def validate(
        self,
        model: torch.nn.Module,
        iteration: int,
        prog: Progress,
    ):
        task = prog.add_task("Validating", total=len(self.dataloader))
        model.eval()
        avg_loss = 0
        for data in self.dataloader:
            img = data["img"].cuda()
            ann = data["ann"].cuda()

            with torch.cuda.amp.autocast(), torch.no_grad():
                pred = self.inferencer.inference(model, img)
                loss = self.criterion(pred, ann).mean()

            self.metrics.compute_and_accum(pred.argmax(1), ann)
            avg_loss += loss.item()
            prog.update(task, advance=1)

        prog.remove_task(task)

        self.img_saver.save_img(img, f"val_{iteration}_image.jpg")
        self.img_saver.save_ann(ann, f"val_{iteration}_ann.png")
        self.img_saver.save_pred(pred, f"val_{iteration}_pred.jpg")

        avg_loss /= len(self.dataloader)

        results = self.metrics.get_and_reset()
        mAcc = sum(results["Acc"]) / len(self.categories)
        mIoU = sum(results["IoU"]) / len(self.categories)
        mDice = sum(results["Dice"]) / len(self.categories)
        mFs = sum(results["Fscore"]) / len(self.categories)
        mPre = sum(results["Precision"]) / len(self.categories)
        mRec = sum(results["Recall"]) / len(self.categories)

        table = Table()
        table.add_column("Id", justify="right")
        table.add_column("Name")
        table.add_column("Acc.")
        table.add_column("IoU")
        table.add_column("Dice")
        table.add_column("Fscore")
        table.add_column("Precision")
        table.add_column("Recall")
        for cat, acc, iou, dice, fs, pre, rec in zip(
            self.categories,
            results["Acc"],
            results["IoU"],
            results["Dice"],
            results["Fscore"],
            results["Precision"],
            results["Recall"],
        ):
            table.add_row(
                str(cat.id),
                cat.name,
                "{:.3f}".format(acc),
                "{:.3f}".format(iou),
                "{:.3f}".format(dice),
                "{:.3f}".format(fs),
                "{:.3f}".format(pre),
                "{:.3f}".format(rec),
            )
        table.add_row(
            "",
            "",
            "{:.3f}".format(mAcc),
            "{:.3f}".format(mIoU),
            "{:.3f}".format(mDice),
            "{:.3f}".format(mFs),
            "{:.3f}".format(mPre),
            "{:.3f}".format(mRec),
        )
        rprint(table)

        self.logger.info("ValLoop", f"Iter: {iteration}, Loss: {avg_loss: .5f}")
        self.logger.tb_log("Val Loss", avg_loss, iteration)
        self.logger.tb_log("Val mAcc", mAcc, iteration)
        self.logger.tb_log("Val mIoU", mIoU, iteration)
        self.logger.tb_log("Val mDice", mDice, iteration)
        self.logger.tb_log("Val mFs", mFs, iteration)
        self.logger.tb_log("Val mPre", mPre, iteration)
        self.logger.tb_log("Val mRec", mRec, iteration)

        # Target validation
        task = prog.add_task("Target Validating", total=len(self.target_dataloader))
        model.eval()
        avg_loss = 0
        for data in self.target_dataloader:
            img = data["img"].cuda()
            ann = data["ann"].cuda()

            with torch.cuda.amp.autocast(), torch.no_grad():
                pred = self.inferencer.inference(model, img)
                loss = self.criterion(pred, ann).mean()

            self.metrics.compute_and_accum(pred.argmax(1), ann)
            avg_loss += loss.item()
            prog.update(task, advance=1)

        self.img_saver.save_img(img, f"target_val_{iteration}_image.jpg")
        self.img_saver.save_ann(ann, f"target_val_{iteration}_ann.png")
        self.img_saver.save_pred(pred, f"target_val_{iteration}_pred.jpg")

        prog.remove_task(task)

        avg_loss /= len(self.dataloader)

        results = self.metrics.get_and_reset()
        mAcc = sum(results["Acc"]) / len(self.categories)
        mIoU = sum(results["IoU"]) / len(self.categories)
        mDice = sum(results["Dice"]) / len(self.categories)
        mFs = sum(results["Fscore"]) / len(self.categories)
        mPre = sum(results["Precision"]) / len(self.categories)
        mRec = sum(results["Recall"]) / len(self.categories)

        table = Table()
        table.add_column("Id", justify="right")
        table.add_column("Name")
        table.add_column("Acc.")
        table.add_column("IoU")
        table.add_column("Dice")
        table.add_column("Fscore")
        table.add_column("Precision")
        table.add_column("Recall")
        for cat, acc, iou, dice, fs, pre, rec in zip(
            self.categories,
            results["Acc"],
            results["IoU"],
            results["Dice"],
            results["Fscore"],
            results["Precision"],
            results["Recall"],
        ):
            table.add_row(
                str(cat.id),
                cat.name,
                "{:.3f}".format(acc),
                "{:.3f}".format(iou),
                "{:.3f}".format(dice),
                "{:.3f}".format(fs),
                "{:.3f}".format(pre),
                "{:.3f}".format(rec),
            )
        table.add_row(
            "",
            "",
            "{:.3f}".format(mAcc),
            "{:.3f}".format(mIoU),
            "{:.3f}".format(mDice),
            "{:.3f}".format(mFs),
            "{:.3f}".format(mPre),
            "{:.3f}".format(mRec),
        )
        rprint(table)

        self.logger.info("TargetValLoop", f"Iter: {iteration}, Loss: {avg_loss: .5f}")
        self.logger.tb_log("Target Val Loss", avg_loss, iteration)
        self.logger.tb_log("Target Val mAcc", mAcc, iteration)
        self.logger.tb_log("Target Val mIoU", mIoU, iteration)
        self.logger.tb_log("Target Val mDice", mDice, iteration)
        self.logger.tb_log("Target Val mFs", mFs, iteration)
        self.logger.tb_log("Target Val mPre", mPre, iteration)
        self.logger.tb_log("Target Val mRec", mRec, iteration)


path_dict = {
    "vpgnet": {
        "csv_path": "data/csv/vpgnet.csv",
        "train_data_root": "data/vpgnet/clear/train",
        "target_train_data_root": "data/vpgnet/night/train",
        "val_data_root": "data/vpgnet/clear/val",
        "target_val_data_root": "data/vpgnet/night/val",
        "img_prefix": "images",
        "ann_prefix": "labels",
        "img_suffix": ".png",
        "ann_suffix": ".png",
    },
    "ceymo": {
        "csv_path": "data/csv/ceymo.csv",
        "train_data_root": "data/ceymo/clear/train",
        "target_train_data_root": "data/ceymo/night/train",
        "val_data_root": "data/ceymo/clear/val",
        "target_val_data_root": "data/ceymo/night/val",
        "img_prefix": "images",
        "ann_prefix": "labels",
        "img_suffix": ".jpg",
        "ann_suffix": ".png",
    },
    "cityscapes_to_acdc_night": {
        "csv_path": "data/csv/cityscapes.csv",
        "train_data_root": "data/cityscapes/train",
        "target_train_data_root": "data/acdc/night/train",
        "val_data_root": "data/cityscapes/val",
        "target_val_data_root": "data/acdc/night/val",
        "img_prefix": "images",
        "ann_prefix": "labels",
        "img_suffix": ".png",
        "ann_suffix": ".png",
    },
}


def main():
    set_seed(0)

    max_iters = 80000
    batch_size = 8
    dataset_name = "ceymo"
    csv_path = path_dict[dataset_name]["csv_path"]
    train_max_length = None
    train_num_workers = batch_size
    val_max_length = None
    log_dir = Path("log/b0_ceymo_clear_to_night_st_norcs_pixelthred_cbst_noisy_round3")
    log_interval = 100
    val_interval = 1000
    checkpoint_interval = 10000
    pin_memory = True

    categories = Category.load(csv_path)
    num_categories = Category.get_num_categories(categories)
    img_scale = (1080, 1920)
    scale = (0.5, 2)
    crop_size = (512, 512)
    stride = (384, 384)

    cfg = dict(
        model_cfg={
            # ----- SegFormer -----
            #
            "name": "segformer",
            "pretrained": "nvidia/mit-b0",
            "num_classes": num_categories,
            #
            # ----- DeepLabV3plus -----
            #
            # ...
            #
        },
        criterion_cfg={
            # ----- CrossEntropy -----
            #
            "name": "cross_entropy_loss",
            "ignore_index": 255,
            "reduction": "mean",
            "label_smoothing": 0,
            #
            # ----- Focal -----
            #
            # "name": "focal_loss",
            # "gamma": 2,
            # "normalized": False,
            #
            # ----- Dice -----
            #
            # "name": "dice_loss",
            #
        },
        inference_cfg={
            # ----- No slide -----
            #
            # "mode": "basic",
            #
            # ----- slide -----
            #
            "mode": "slide",
            "crop_size": crop_size,
            "stride": stride,
            "num_categories": num_categories,
            #
        },
        ema_cfg=dict(
            # alpha=0.999,
            alpha=1,
            warmup=0,
            soft_loss_weight=1,
            entropy_loss_weight=0,
            # ----- No thresolding -----
            #
            # soft_loss_computer=dict(name="NoThreshold"),
            #
            # ----- global thresolding -----
            #
            # soft_loss_computer=dict(name="GlobalThreshold", threshold=0.9),
            # soft_loss_computer=dict(
            #     name="GlobalThreshold",
            #     threshold=[
            #         0.9998092055,
            #         0.9477541447,
            #         0.5106793046,
            #         0.6060999036,
            #         0.9884882569,
            #         0.5496154428,
            #         0.6360917091,
            #         0.5154536366,
            #         0.9936053753,
            #         0.8256868124,
            #         0.8537654877,
            #         0.5328435898,
            #     ],
            # ),
            #
            # ----- pixel-wise thresolding -----
            #
            # soft_loss_computer=dict(name="PixelThreshold", threshold=0.968),
            soft_loss_computer=dict(
                name="PixelThreshold",
                threshold=[
                    # round3      # round2        # round1
                    1.0000000000, # 0.9999998808, # 0.9999990463,
                    0.9961261153, # 0.8862618208, # 0.9703385830,
                    0.8554342389, # 0.9110013843, # 0.7615851760,
                    0.9966099858, # 0.9893469214, # 0.9882054329,
                    0.9999709129, # 0.9970429540, # 0.9996004701,
                    0.8684976101, # 0.7839401960, # 0.8491899967,
                    0.9999476671, # 0.9992212057, # 0.9998764992,
                    0.8417629600, # 0.5788171291, # 0.5178074837,
                    0.9901699424, # 0.9434673786, # 0.9888495803,
                    0.6976749301, # 0.7789289355, # 0.7988175750,
                    0.6831156015, # 0.5410201550, # 0.8970751166,
                    0.8818159103, # 0.6559101343, # 0.5653188825,
                ],  # fmt: skip
            ),
            #
            entropy_loss_computer=dict(name="BasicEntropy"),
        ),
        # rcs_cfg=RCSConfig(
        #     file_path="vpgnet.json",
        #     ignore_ids=[0],
        #     temperature=0.5,
        # ),
    )

    if "rcs_cfg" not in cfg:
        train_dataloader = ImgAnnDataset(
            root=path_dict[dataset_name]["train_data_root"],
            img_prefix=path_dict[dataset_name]["img_prefix"],
            ann_prefix=path_dict[dataset_name]["ann_prefix"],
            img_suffix=path_dict[dataset_name]["img_suffix"],
            ann_suffix=path_dict[dataset_name]["ann_suffix"],
            transforms=[
                transform.LoadImg(),
                transform.LoadAnn(categories),
                transform.RandomResizeCrop(
                    img_scale,
                    scale,
                    crop_size,
                ),
                transform.ColorJitter(
                    brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1
                ),
                transform.RandomGaussian(kernel_size=5),
                transform.Normalize(),
            ],
            max_len=train_max_length,
        ).get_loader(
            batch_size=batch_size,
            shuffle=True,
            num_workers=train_num_workers,
            drop_last=True,
            pin_memory=pin_memory,
            infinite=True,
        )
    else:
        train_dataloader = RCSImgAnnDataset(
            root=path_dict[dataset_name]["train_data_root"],
            img_prefix=path_dict[dataset_name]["img_prefix"],
            ann_prefix=path_dict[dataset_name]["ann_prefix"],
            img_suffix=path_dict[dataset_name]["img_suffix"],
            ann_suffix=path_dict[dataset_name]["ann_suffix"],
            transforms=[
                transform.LoadImg(),
                transform.LoadAnn(categories),
                transform.RandomResizeCrop(
                    img_scale,
                    scale,
                    crop_size,
                ),
                transform.ColorJitter(
                    brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1
                ),
                transform.RandomGaussian(kernel_size=5),
                transform.Normalize(),
            ],
            categories=categories,
            rcs_cfg=cfg["rcs_cfg"],
            show_rcs=True,
        ).get_loader(
            batch_size=batch_size,
            shuffle=True,
            num_workers=train_num_workers,
            drop_last=True,
            pin_memory=pin_memory,
            infinite=True,
        )

    target_train_dataloader = ImgAnnDataset(
        root=path_dict[dataset_name]["target_train_data_root"],
        img_prefix=path_dict[dataset_name]["img_prefix"],
        ann_prefix=path_dict[dataset_name]["ann_prefix"],
        img_suffix=path_dict[dataset_name]["img_suffix"],
        ann_suffix=path_dict[dataset_name]["ann_suffix"],
        transforms=[
            transform.LoadImg(),
            transform.RandomResizeCrop(
                img_scale,
                scale,
                crop_size,
            ),
            transform.Normalize(),
        ],
        check_exist=False,
        max_len=train_max_length,
    ).get_loader(
        batch_size=batch_size,
        shuffle=True,
        num_workers=train_num_workers,
        drop_last=True,
        pin_memory=pin_memory,
        infinite=True,
    )

    val_dataloader = ImgAnnDataset(
        root=path_dict[dataset_name]["val_data_root"],
        img_prefix=path_dict[dataset_name]["img_prefix"],
        ann_prefix=path_dict[dataset_name]["ann_prefix"],
        img_suffix=path_dict[dataset_name]["img_suffix"],
        ann_suffix=path_dict[dataset_name]["ann_suffix"],
        transforms=[
            transform.LoadImg(),
            transform.LoadAnn(categories),
            transform.Resize(),
            transform.Normalize(),
        ],
        max_len=val_max_length,
    ).get_loader(
        batch_size=4,
        shuffle=False,
        num_workers=4,
        drop_last=False,
        pin_memory=pin_memory,
    )

    target_val_dataloader = ImgAnnDataset(
        root=path_dict[dataset_name]["target_val_data_root"],
        img_prefix=path_dict[dataset_name]["img_prefix"],
        ann_prefix=path_dict[dataset_name]["ann_prefix"],
        img_suffix=path_dict[dataset_name]["img_suffix"],
        ann_suffix=path_dict[dataset_name]["ann_suffix"],
        transforms=[
            transform.LoadImg(),
            transform.LoadAnn(categories),
            transform.Resize(),
            transform.Normalize(),
        ],
        max_len=val_max_length,
    ).get_loader(
        batch_size=4,
        shuffle=False,
        num_workers=4,
        drop_last=False,
        pin_memory=pin_memory,
    )

    model = builder.build_model(cfg["model_cfg"]).cuda()
    if "ema_cfg" in cfg:
        # ema = builder.build_ema_model(cfg["model_cfg"], cfg["ema_cfg"]).cuda()
        ema = EMA(
            model, beta=cfg["ema_cfg"]["alpha"], update_after_step=-1, update_every=1
        )
        ema.ema_model.load_state_dict(
            torch.load(
                "log/b0_ceymo_clear_to_night_st_norcs_pixelthred_cbst_noisy_round2/latest.pth"
            )
        )
        ema.register_buffer("initted", torch.tensor(True))
        soft_loss_computer = builder.build_soft_loss_computer(
            cfg["ema_cfg"]["soft_loss_computer"]
        )
        entropy_loss_computer = builder.build_entropy_loss_computer(
            cfg["ema_cfg"]["entropy_loss_computer"]
        )

    criterion = builder.build_criterion(cfg["criterion_cfg"]).cuda()

    optimizer = AdamW(
        [
            {"params": model.segformer.parameters(), "lr": 6e-5},
            {"params": model.decode_head.parameters(), "lr": 6e-4},
        ],
    )
    warmup_scheduler = torch.optim.lr_scheduler.LinearLR(
        optimizer.torch(), 1e-4, 1, 1500
    )
    poly_scheduler = torch.optim.lr_scheduler.PolynomialLR(
        optimizer.torch(), max_iters, 1
    )

    inferencer = builder.build_inferencer(cfg["inference_cfg"])
    metrics = Metrics(num_categories, 255, nan_to_num=0)

    logger = Logger(log_dir)
    img_saver = ImgSaver(root=log_dir, visualizer=IdMapVisualizer(categories))

    validator = Validator(
        val_dataloader,
        target_val_dataloader,
        criterion,
        inferencer,
        metrics,
        img_saver,
        categories,
        logger,
    )

    with Progress() as prog:
        train_task = prog.add_task("Training", total=max_iters)

        for it in range(1, max_iters + 1, 1):
            if "ema_cfg" in cfg and it > cfg["ema_cfg"]["warmup"]:
                ema.update()

            data = next(train_dataloader)
            try:
                results = train_iter(
                    data["img"],
                    data["ann"],
                    model,
                    criterion,
                    optimizer,
                )
            except NanException as e:
                logger.error("TrainLoop", str(e))
                logger.error(
                    "TrainLoop", "Got NaN loss when source training! Training ends."
                )
                break

            if it % log_interval == 0:
                img_saver.save_img(results.pop("Img"), f"train_{it}_img.jpg")
                img_saver.save_ann(results.pop("Ann"), f"train_{it}_ann.jpg")
                img_saver.save_pred(results.pop("Pred"), f"train_{it}_pred.jpg")
                log = "Iteration: {}".format(it)
                for k, v in results.items():
                    log += ", {}: {:.5f}".format(k, v)
                    logger.tb_log("Train " + k, v, it)

            if "ema_cfg" in cfg and it > cfg["ema_cfg"]["warmup"]:
                data = next(target_train_dataloader)
                try:
                    results = pseudo_train_iter(
                        data["img"],
                        model,
                        ema,
                        criterion,
                        optimizer,
                        # data["strong_img"],
                        soft_loss_computer=soft_loss_computer,
                        weight=cfg["ema_cfg"]["soft_loss_weight"],
                        entropy_loss_computer=entropy_loss_computer,
                        entropy_weight=cfg["ema_cfg"]["entropy_loss_weight"],
                    )

                except NanException as e:
                    logger.error("TrainLoop", str(e))
                    logger.error(
                        "TrainLoop", "Got NaN loss when target training! Training ends."
                    )
                    break

                if it % log_interval == 0:
                    img_saver.save_img(results.pop("Img"), f"train_ps_{it}_img.jpg")
                    img_saver.save_ann(results.pop("Ann"), f"train_ps_{it}_ann.jpg")
                    img_saver.save_heatmap(
                        results.pop("Ann Conf"), f"train_ps_{it}_ann_conf.jpg"
                    )
                    img_saver.save_heatmap(
                        results.pop("Entropy Map"), f"train_ps_{it}_ann_entropy.jpg"
                    )
                    img_saver.save_pred(results.pop("Pred"), f"train_ps_{it}_pred.jpg")
                    # img_saver.save_img(
                    #     results.pop("Strong Img"), f"train_ps_{it}_strong_img.jpg"
                    # )
                    # img_saver.save_pred(
                    #     results.pop("Strong Pred"), f"train_ps_{it}_strong_pred.jpg"
                    # )
                    for k, v in results.items():
                        log += ", {}: {:.5f}".format("Pseudo " + k, v)
                        logger.tb_log("Train Pseudo " + k, v, it)

            if it % log_interval == 0:
                logger.info("TrainLoop", log)

            warmup_scheduler.step()
            poly_scheduler.step()

            if it % val_interval == 0:
                validator.validate(model, it, prog)

            if it % checkpoint_interval == 0:
                torch.save(model.state_dict(), log_dir / f"iter_{it}.pth")

            torch.save(model.state_dict(), log_dir / "latest.pth")

            prog.update(train_task, completed=it)


if __name__ == "__main__":

    main()
